{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAST30034 Final Project\n",
    "#### Pre processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/sherinclaudia/using-tf-idf-vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all standard libraries\n",
    "from datetime import datetime, date, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import feather\n",
    "import nltk\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "# Import all packages needed here\n",
    "from datetime import datetime, date, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import feather\n",
    "import nltk\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline cleaned data\n",
    "data = pd.read_csv(\"data/cleaned-train-balanced-sarcasm-baseline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned data\n",
    "data = pd.read_csv(\"data/cleaned-train-balanced-sarcasm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data\n",
    "data = pd.read_csv(\"data/train-balanced-sarcasm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc2vec feature\n",
    "d2v_features = pd.read_csv(\"doc_emb_64_4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1010821</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm sure that Iran and N. Korea have the techn...</td>\n",
       "      <td>TwarkMain</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-25 00:47:52</td>\n",
       "      <td>No one is calling this an engineered pathogen,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010822</th>\n",
       "      <td>1</td>\n",
       "      <td>whatever you do, don't vote green!</td>\n",
       "      <td>BCHarvey</td>\n",
       "      <td>climate</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-05</td>\n",
       "      <td>2009-05-14 22:27:40</td>\n",
       "      <td>In a move typical of their recent do-nothing a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010823</th>\n",
       "      <td>1</td>\n",
       "      <td>Perhaps this is an atheist conspiracy to make ...</td>\n",
       "      <td>rebelcommander</td>\n",
       "      <td>atheism</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01</td>\n",
       "      <td>2009-01-11 00:22:57</td>\n",
       "      <td>Screw the Disabled--I've got to get to Church ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010824</th>\n",
       "      <td>1</td>\n",
       "      <td>The Slavs got their own country - it is called...</td>\n",
       "      <td>catsi</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01</td>\n",
       "      <td>2009-01-23 21:12:49</td>\n",
       "      <td>I've always been unsettled by that. I hear a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010825</th>\n",
       "      <td>1</td>\n",
       "      <td>values, as in capitalism .. there is good mone...</td>\n",
       "      <td>frogking</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01</td>\n",
       "      <td>2009-01-24 06:20:14</td>\n",
       "      <td>Why do the people who make our laws seem unabl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                            comment  \\\n",
       "1010821      1  I'm sure that Iran and N. Korea have the techn...   \n",
       "1010822      1                 whatever you do, don't vote green!   \n",
       "1010823      1  Perhaps this is an atheist conspiracy to make ...   \n",
       "1010824      1  The Slavs got their own country - it is called...   \n",
       "1010825      1  values, as in capitalism .. there is good mone...   \n",
       "\n",
       "                 author   subreddit  score  ups  downs     date  \\\n",
       "1010821       TwarkMain  reddit.com      2    2      0  2009-04   \n",
       "1010822        BCHarvey     climate      1    1      0  2009-05   \n",
       "1010823  rebelcommander     atheism      1    1      0  2009-01   \n",
       "1010824           catsi   worldnews      1    1      0  2009-01   \n",
       "1010825        frogking    politics      2    2      0  2009-01   \n",
       "\n",
       "                 created_utc  \\\n",
       "1010821  2009-04-25 00:47:52   \n",
       "1010822  2009-05-14 22:27:40   \n",
       "1010823  2009-01-11 00:22:57   \n",
       "1010824  2009-01-23 21:12:49   \n",
       "1010825  2009-01-24 06:20:14   \n",
       "\n",
       "                                            parent_comment  \n",
       "1010821  No one is calling this an engineered pathogen,...  \n",
       "1010822  In a move typical of their recent do-nothing a...  \n",
       "1010823  Screw the Disabled--I've got to get to Church ...  \n",
       "1010824  I've always been unsettled by that. I hear a l...  \n",
       "1010825  Why do the people who make our laws seem unabl...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.025234</td>\n",
       "      <td>0.037236</td>\n",
       "      <td>-0.018450</td>\n",
       "      <td>0.004195</td>\n",
       "      <td>-0.003338</td>\n",
       "      <td>0.019497</td>\n",
       "      <td>-0.002063</td>\n",
       "      <td>-0.005147</td>\n",
       "      <td>-0.001476</td>\n",
       "      <td>-0.003548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011302</td>\n",
       "      <td>0.018709</td>\n",
       "      <td>-0.007005</td>\n",
       "      <td>-0.011381</td>\n",
       "      <td>0.012025</td>\n",
       "      <td>-0.005126</td>\n",
       "      <td>-0.015022</td>\n",
       "      <td>-0.006073</td>\n",
       "      <td>0.002279</td>\n",
       "      <td>-0.005415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.043852</td>\n",
       "      <td>0.047373</td>\n",
       "      <td>-0.064609</td>\n",
       "      <td>-0.074188</td>\n",
       "      <td>-0.114226</td>\n",
       "      <td>0.024434</td>\n",
       "      <td>-0.019833</td>\n",
       "      <td>0.043862</td>\n",
       "      <td>-0.004325</td>\n",
       "      <td>0.003651</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071348</td>\n",
       "      <td>0.073148</td>\n",
       "      <td>-0.061100</td>\n",
       "      <td>-0.007161</td>\n",
       "      <td>0.042210</td>\n",
       "      <td>-0.072359</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>-0.076472</td>\n",
       "      <td>0.054566</td>\n",
       "      <td>-0.002896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.075531</td>\n",
       "      <td>0.053695</td>\n",
       "      <td>-0.092345</td>\n",
       "      <td>-0.025676</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.016434</td>\n",
       "      <td>-0.024780</td>\n",
       "      <td>-0.035500</td>\n",
       "      <td>0.010457</td>\n",
       "      <td>-0.018448</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050567</td>\n",
       "      <td>-0.021944</td>\n",
       "      <td>-0.024762</td>\n",
       "      <td>-0.013558</td>\n",
       "      <td>0.016077</td>\n",
       "      <td>-0.018084</td>\n",
       "      <td>-0.043640</td>\n",
       "      <td>-0.042980</td>\n",
       "      <td>-0.001261</td>\n",
       "      <td>-0.073530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025550</td>\n",
       "      <td>0.006054</td>\n",
       "      <td>0.011279</td>\n",
       "      <td>0.030003</td>\n",
       "      <td>0.053378</td>\n",
       "      <td>0.034148</td>\n",
       "      <td>0.020962</td>\n",
       "      <td>0.010467</td>\n",
       "      <td>0.004046</td>\n",
       "      <td>-0.025119</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010853</td>\n",
       "      <td>-0.046720</td>\n",
       "      <td>-0.005760</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>0.002937</td>\n",
       "      <td>-0.026624</td>\n",
       "      <td>-0.035406</td>\n",
       "      <td>0.045522</td>\n",
       "      <td>-0.008202</td>\n",
       "      <td>0.016417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.040980</td>\n",
       "      <td>0.045497</td>\n",
       "      <td>-0.022521</td>\n",
       "      <td>-0.021297</td>\n",
       "      <td>-0.039178</td>\n",
       "      <td>0.017603</td>\n",
       "      <td>0.011009</td>\n",
       "      <td>0.014564</td>\n",
       "      <td>0.026795</td>\n",
       "      <td>0.004767</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030013</td>\n",
       "      <td>0.029787</td>\n",
       "      <td>-0.034320</td>\n",
       "      <td>-0.002205</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>-0.014847</td>\n",
       "      <td>0.006308</td>\n",
       "      <td>0.005798</td>\n",
       "      <td>0.019065</td>\n",
       "      <td>0.003529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005609</th>\n",
       "      <td>0.033414</td>\n",
       "      <td>0.024973</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>0.013191</td>\n",
       "      <td>0.024706</td>\n",
       "      <td>-0.017869</td>\n",
       "      <td>-0.037586</td>\n",
       "      <td>-0.017890</td>\n",
       "      <td>-0.018741</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006415</td>\n",
       "      <td>-0.011320</td>\n",
       "      <td>-0.029963</td>\n",
       "      <td>0.016686</td>\n",
       "      <td>-0.056395</td>\n",
       "      <td>0.043691</td>\n",
       "      <td>0.022048</td>\n",
       "      <td>0.023134</td>\n",
       "      <td>0.017265</td>\n",
       "      <td>0.036359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005610</th>\n",
       "      <td>-0.022911</td>\n",
       "      <td>-0.045893</td>\n",
       "      <td>-0.029147</td>\n",
       "      <td>0.031376</td>\n",
       "      <td>-0.013374</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>-0.001083</td>\n",
       "      <td>-0.037461</td>\n",
       "      <td>0.010970</td>\n",
       "      <td>-0.032507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010211</td>\n",
       "      <td>0.044021</td>\n",
       "      <td>-0.028827</td>\n",
       "      <td>0.015161</td>\n",
       "      <td>0.013867</td>\n",
       "      <td>-0.030684</td>\n",
       "      <td>0.021098</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.008206</td>\n",
       "      <td>-0.017253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005611</th>\n",
       "      <td>-0.031084</td>\n",
       "      <td>0.058907</td>\n",
       "      <td>-0.031200</td>\n",
       "      <td>-0.029260</td>\n",
       "      <td>-0.023967</td>\n",
       "      <td>0.029163</td>\n",
       "      <td>0.014836</td>\n",
       "      <td>-0.020794</td>\n",
       "      <td>0.004977</td>\n",
       "      <td>0.009315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031404</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>-0.026510</td>\n",
       "      <td>0.051405</td>\n",
       "      <td>0.017607</td>\n",
       "      <td>-0.004577</td>\n",
       "      <td>0.011467</td>\n",
       "      <td>-0.011458</td>\n",
       "      <td>0.010909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005612</th>\n",
       "      <td>-0.006779</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>-0.000569</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>-0.004019</td>\n",
       "      <td>0.016414</td>\n",
       "      <td>-0.003037</td>\n",
       "      <td>0.006816</td>\n",
       "      <td>-0.026500</td>\n",
       "      <td>-0.022377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019768</td>\n",
       "      <td>0.016280</td>\n",
       "      <td>0.019824</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>-0.023218</td>\n",
       "      <td>0.008182</td>\n",
       "      <td>0.007085</td>\n",
       "      <td>-0.020306</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>-0.017950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005613</th>\n",
       "      <td>0.012667</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>-0.010289</td>\n",
       "      <td>-0.001951</td>\n",
       "      <td>-0.033486</td>\n",
       "      <td>-0.005680</td>\n",
       "      <td>0.010307</td>\n",
       "      <td>0.012345</td>\n",
       "      <td>-0.014124</td>\n",
       "      <td>-0.009440</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017501</td>\n",
       "      <td>0.046749</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>-0.001644</td>\n",
       "      <td>-0.002261</td>\n",
       "      <td>-0.007316</td>\n",
       "      <td>-0.009782</td>\n",
       "      <td>-0.028838</td>\n",
       "      <td>-0.000888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1005614 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5         6  \\\n",
       "0       -0.025234  0.037236 -0.018450  0.004195 -0.003338  0.019497 -0.002063   \n",
       "1       -0.043852  0.047373 -0.064609 -0.074188 -0.114226  0.024434 -0.019833   \n",
       "2       -0.075531  0.053695 -0.092345 -0.025676  0.001137  0.016434 -0.024780   \n",
       "3        0.025550  0.006054  0.011279  0.030003  0.053378  0.034148  0.020962   \n",
       "4       -0.040980  0.045497 -0.022521 -0.021297 -0.039178  0.017603  0.011009   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "1005609  0.033414  0.024973  0.013542  0.013191  0.024706 -0.017869 -0.037586   \n",
       "1005610 -0.022911 -0.045893 -0.029147  0.031376 -0.013374  0.003704 -0.001083   \n",
       "1005611 -0.031084  0.058907 -0.031200 -0.029260 -0.023967  0.029163  0.014836   \n",
       "1005612 -0.006779  0.002102 -0.000569  0.007489 -0.004019  0.016414 -0.003037   \n",
       "1005613  0.012667  0.004906 -0.010289 -0.001951 -0.033486 -0.005680  0.010307   \n",
       "\n",
       "                7         8         9  ...        54        55        56  \\\n",
       "0       -0.005147 -0.001476 -0.003548  ... -0.011302  0.018709 -0.007005   \n",
       "1        0.043862 -0.004325  0.003651  ... -0.071348  0.073148 -0.061100   \n",
       "2       -0.035500  0.010457 -0.018448  ... -0.050567 -0.021944 -0.024762   \n",
       "3        0.010467  0.004046 -0.025119  ... -0.010853 -0.046720 -0.005760   \n",
       "4        0.014564  0.026795  0.004767  ... -0.030013  0.029787 -0.034320   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "1005609 -0.017890 -0.018741  0.008152  ... -0.006415 -0.011320 -0.029963   \n",
       "1005610 -0.037461  0.010970 -0.032507  ...  0.010211  0.044021 -0.028827   \n",
       "1005611 -0.020794  0.004977  0.009315  ... -0.031404  0.012811  0.006939   \n",
       "1005612  0.006816 -0.026500 -0.022377  ...  0.019768  0.016280  0.019824   \n",
       "1005613  0.012345 -0.014124 -0.009440  ... -0.017501  0.046749  0.002679   \n",
       "\n",
       "               57        58        59        60        61        62        63  \n",
       "0       -0.011381  0.012025 -0.005126 -0.015022 -0.006073  0.002279 -0.005415  \n",
       "1       -0.007161  0.042210 -0.072359  0.006267 -0.076472  0.054566 -0.002896  \n",
       "2       -0.013558  0.016077 -0.018084 -0.043640 -0.042980 -0.001261 -0.073530  \n",
       "3       -0.012105  0.002937 -0.026624 -0.035406  0.045522 -0.008202  0.016417  \n",
       "4       -0.002205  0.006251 -0.014847  0.006308  0.005798  0.019065  0.003529  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "1005609  0.016686 -0.056395  0.043691  0.022048  0.023134  0.017265  0.036359  \n",
       "1005610  0.015161  0.013867 -0.030684  0.021098  0.000763  0.008206 -0.017253  \n",
       "1005611 -0.026510  0.051405  0.017607 -0.004577  0.011467 -0.011458  0.010909  \n",
       "1005612  0.002704 -0.023218  0.008182  0.007085 -0.020306  0.013123 -0.017950  \n",
       "1005613  0.001505 -0.001644 -0.002261 -0.007316 -0.009782 -0.028838 -0.000888  \n",
       "\n",
       "[1005614 rows x 64 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v_features.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NAs\n",
    "data.dropna(subset=['comment'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>868</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>0</td>\n",
       "      <td>39014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>869</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>1</td>\n",
       "      <td>26305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18385</td>\n",
       "      <td>politics</td>\n",
       "      <td>1</td>\n",
       "      <td>23885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21533</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>1</td>\n",
       "      <td>16942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18384</td>\n",
       "      <td>politics</td>\n",
       "      <td>0</td>\n",
       "      <td>15554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>11bx1371</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>112263Hulu</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>100pushups</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0x3642</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>07Scape</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21749 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        subreddit  label  comment\n",
       "868     AskReddit      0    39014\n",
       "869     AskReddit      1    26305\n",
       "18385    politics      1    23885\n",
       "21533   worldnews      1    16942\n",
       "18384    politics      0    15554\n",
       "...           ...    ...      ...\n",
       "14       11bx1371      0        1\n",
       "13     112263Hulu      1        1\n",
       "4      100pushups      0        1\n",
       "2          0x3642      0        1\n",
       "0         07Scape      0        1\n",
       "\n",
       "[21749 rows x 3 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['subreddit', 'label'])['comment'].count().reset_index().sort_values(by=['comment', 'subreddit', 'label'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying tf-idf vectorizer\n",
    "tf_idf = TfidfVectorizer(ngram_range=(1, 2), max_features=50000, min_df=2)\n",
    "\n",
    "#applying logistic regression\n",
    "logit = LogisticRegression(C=1, n_jobs=4, solver='lbfgs', \n",
    "                           random_state=17, verbose=1)\n",
    "\n",
    "#applying multinomial naive bayes\n",
    "# alpha=1 is laplace smoothing, <1 is lidstone smoothing\n",
    "mNB = MultinomialNB(alpha=1)\n",
    "\n",
    "#applying RandomForest for classification\n",
    "ranforest = RandomForestClassifier(n_jobs=4,random_state=15, max_depth = 10)\n",
    "\n",
    "#applying SVM for classification\n",
    "svm = SVC(gamma='auto')\n",
    "\n",
    "#pipelining\n",
    "tfidf_logit_pipeline = Pipeline([('tf_idf', tf_idf), \n",
    "                                 ('logit', logit)])\n",
    "\n",
    "tfidf_mNB_pipeline = Pipeline([('tf_idf', tf_idf), \n",
    "                                 ('mnb', mNB)])\n",
    "\n",
    "tfidf_svm_pipeline = Pipeline([('tf_idf', tf_idf), \n",
    "                                 ('svm', svm)])\n",
    "\n",
    "tfidf_ranforest_pipeline = Pipeline([('tf_idf', tf_idf), \n",
    "                                 ('ranforest', ranforest)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=['comment'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                      int64\n",
       "comment                   object\n",
       "subreddit                 object\n",
       "score                      int64\n",
       "ups                        int64\n",
       "downs                      int64\n",
       "created_utc               object\n",
       "parent_comment            object\n",
       "year                       int64\n",
       "month                      int64\n",
       "day                        int64\n",
       "hour                       int64\n",
       "cleaned comment           object\n",
       "cleaned parent comment    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.astype({'cleaned comment': 'U', 'cleaned parent comment': 'U'})\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, valid_texts, y_train, y_valid = train_test_split(data['cleaned comment'], data['label'], random_state=15, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for doc2vec features\n",
    "X_train, X_test,Y_train, Y_test = train_test_split(d2v_features, data['label'], random_state=15, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>898657</th>\n",
       "      <td>-0.083976</td>\n",
       "      <td>0.060627</td>\n",
       "      <td>-0.047165</td>\n",
       "      <td>-0.032120</td>\n",
       "      <td>-0.075049</td>\n",
       "      <td>-0.002558</td>\n",
       "      <td>0.034063</td>\n",
       "      <td>0.014356</td>\n",
       "      <td>0.039806</td>\n",
       "      <td>0.032403</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005498</td>\n",
       "      <td>0.039072</td>\n",
       "      <td>-0.037041</td>\n",
       "      <td>-0.010917</td>\n",
       "      <td>0.016998</td>\n",
       "      <td>-0.008719</td>\n",
       "      <td>0.024508</td>\n",
       "      <td>-0.019502</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.024847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193195</th>\n",
       "      <td>0.010582</td>\n",
       "      <td>-0.030575</td>\n",
       "      <td>0.020016</td>\n",
       "      <td>0.019928</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>0.029363</td>\n",
       "      <td>-0.009639</td>\n",
       "      <td>0.030029</td>\n",
       "      <td>-0.009430</td>\n",
       "      <td>-0.024412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020975</td>\n",
       "      <td>0.004946</td>\n",
       "      <td>-0.005037</td>\n",
       "      <td>-0.005273</td>\n",
       "      <td>-0.005645</td>\n",
       "      <td>-0.037620</td>\n",
       "      <td>-0.064985</td>\n",
       "      <td>0.021778</td>\n",
       "      <td>0.016151</td>\n",
       "      <td>-0.033996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356268</th>\n",
       "      <td>-0.077585</td>\n",
       "      <td>-0.026994</td>\n",
       "      <td>-0.073639</td>\n",
       "      <td>0.056975</td>\n",
       "      <td>0.046887</td>\n",
       "      <td>-0.016993</td>\n",
       "      <td>0.062116</td>\n",
       "      <td>0.056346</td>\n",
       "      <td>-0.002153</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044716</td>\n",
       "      <td>-0.006357</td>\n",
       "      <td>0.005816</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>0.042469</td>\n",
       "      <td>-0.016254</td>\n",
       "      <td>0.056720</td>\n",
       "      <td>0.025408</td>\n",
       "      <td>0.056422</td>\n",
       "      <td>-0.011064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131507</th>\n",
       "      <td>-0.048274</td>\n",
       "      <td>0.058991</td>\n",
       "      <td>-0.067685</td>\n",
       "      <td>-0.015328</td>\n",
       "      <td>-0.033801</td>\n",
       "      <td>0.023853</td>\n",
       "      <td>0.025454</td>\n",
       "      <td>0.041669</td>\n",
       "      <td>0.044017</td>\n",
       "      <td>0.069551</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039678</td>\n",
       "      <td>0.075478</td>\n",
       "      <td>-0.005082</td>\n",
       "      <td>-0.025937</td>\n",
       "      <td>0.021439</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>0.010402</td>\n",
       "      <td>0.021534</td>\n",
       "      <td>0.040205</td>\n",
       "      <td>-0.018626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471772</th>\n",
       "      <td>-0.026412</td>\n",
       "      <td>0.028603</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>0.009612</td>\n",
       "      <td>0.007720</td>\n",
       "      <td>0.028920</td>\n",
       "      <td>0.041640</td>\n",
       "      <td>0.016288</td>\n",
       "      <td>-0.005515</td>\n",
       "      <td>-0.015099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024378</td>\n",
       "      <td>0.019679</td>\n",
       "      <td>0.004347</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>-0.006012</td>\n",
       "      <td>0.018145</td>\n",
       "      <td>0.013360</td>\n",
       "      <td>-0.006049</td>\n",
       "      <td>-0.022244</td>\n",
       "      <td>0.020143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704375</th>\n",
       "      <td>-0.024381</td>\n",
       "      <td>0.077858</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>-0.011786</td>\n",
       "      <td>-0.025302</td>\n",
       "      <td>-0.015964</td>\n",
       "      <td>0.010275</td>\n",
       "      <td>0.025782</td>\n",
       "      <td>0.004504</td>\n",
       "      <td>0.009907</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045996</td>\n",
       "      <td>0.019012</td>\n",
       "      <td>-0.022544</td>\n",
       "      <td>-0.023323</td>\n",
       "      <td>0.026188</td>\n",
       "      <td>-0.025225</td>\n",
       "      <td>0.092622</td>\n",
       "      <td>0.038373</td>\n",
       "      <td>-0.015977</td>\n",
       "      <td>0.023654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199301</th>\n",
       "      <td>-0.013455</td>\n",
       "      <td>0.017545</td>\n",
       "      <td>-0.015423</td>\n",
       "      <td>-0.022008</td>\n",
       "      <td>-0.019408</td>\n",
       "      <td>0.003504</td>\n",
       "      <td>0.013235</td>\n",
       "      <td>-0.002673</td>\n",
       "      <td>0.010532</td>\n",
       "      <td>0.017836</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006550</td>\n",
       "      <td>0.028809</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.012445</td>\n",
       "      <td>0.019952</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.015746</td>\n",
       "      <td>-0.009257</td>\n",
       "      <td>-0.002102</td>\n",
       "      <td>0.005940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794508</th>\n",
       "      <td>-0.002972</td>\n",
       "      <td>0.018097</td>\n",
       "      <td>-0.016907</td>\n",
       "      <td>-0.016020</td>\n",
       "      <td>-0.032671</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>0.014023</td>\n",
       "      <td>0.007179</td>\n",
       "      <td>0.007476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007305</td>\n",
       "      <td>0.032531</td>\n",
       "      <td>-0.007571</td>\n",
       "      <td>-0.011182</td>\n",
       "      <td>0.013380</td>\n",
       "      <td>-0.025935</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>-0.019615</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>-0.005441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446197</th>\n",
       "      <td>-0.042256</td>\n",
       "      <td>0.030980</td>\n",
       "      <td>-0.052531</td>\n",
       "      <td>-0.000446</td>\n",
       "      <td>-0.071554</td>\n",
       "      <td>0.003265</td>\n",
       "      <td>0.016964</td>\n",
       "      <td>-0.015440</td>\n",
       "      <td>0.016752</td>\n",
       "      <td>0.009769</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012209</td>\n",
       "      <td>0.033215</td>\n",
       "      <td>-0.021941</td>\n",
       "      <td>-0.001283</td>\n",
       "      <td>0.032435</td>\n",
       "      <td>-0.015799</td>\n",
       "      <td>-0.005708</td>\n",
       "      <td>-0.025815</td>\n",
       "      <td>-0.009696</td>\n",
       "      <td>0.001321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794056</th>\n",
       "      <td>-0.028520</td>\n",
       "      <td>0.025804</td>\n",
       "      <td>0.036703</td>\n",
       "      <td>-0.031924</td>\n",
       "      <td>-0.043415</td>\n",
       "      <td>0.023052</td>\n",
       "      <td>0.025876</td>\n",
       "      <td>0.060736</td>\n",
       "      <td>-0.003931</td>\n",
       "      <td>0.007093</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002388</td>\n",
       "      <td>0.063318</td>\n",
       "      <td>-0.043061</td>\n",
       "      <td>-0.001999</td>\n",
       "      <td>-0.006753</td>\n",
       "      <td>-0.039547</td>\n",
       "      <td>0.050413</td>\n",
       "      <td>0.048766</td>\n",
       "      <td>0.043618</td>\n",
       "      <td>0.008088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>804491 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "898657 -0.083976  0.060627 -0.047165 -0.032120 -0.075049 -0.002558  0.034063   \n",
       "193195  0.010582 -0.030575  0.020016  0.019928  0.002720  0.029363 -0.009639   \n",
       "356268 -0.077585 -0.026994 -0.073639  0.056975  0.046887 -0.016993  0.062116   \n",
       "131507 -0.048274  0.058991 -0.067685 -0.015328 -0.033801  0.023853  0.025454   \n",
       "471772 -0.026412  0.028603  0.005906  0.009612  0.007720  0.028920  0.041640   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "704375 -0.024381  0.077858  0.008986 -0.011786 -0.025302 -0.015964  0.010275   \n",
       "199301 -0.013455  0.017545 -0.015423 -0.022008 -0.019408  0.003504  0.013235   \n",
       "794508 -0.002972  0.018097 -0.016907 -0.016020 -0.032671  0.002122  0.009174   \n",
       "446197 -0.042256  0.030980 -0.052531 -0.000446 -0.071554  0.003265  0.016964   \n",
       "794056 -0.028520  0.025804  0.036703 -0.031924 -0.043415  0.023052  0.025876   \n",
       "\n",
       "               7         8         9  ...        54        55        56  \\\n",
       "898657  0.014356  0.039806  0.032403  ... -0.005498  0.039072 -0.037041   \n",
       "193195  0.030029 -0.009430 -0.024412  ...  0.020975  0.004946 -0.005037   \n",
       "356268  0.056346 -0.002153  0.003948  ... -0.044716 -0.006357  0.005816   \n",
       "131507  0.041669  0.044017  0.069551  ... -0.039678  0.075478 -0.005082   \n",
       "471772  0.016288 -0.005515 -0.015099  ...  0.024378  0.019679  0.004347   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "704375  0.025782  0.004504  0.009907  ... -0.045996  0.019012 -0.022544   \n",
       "199301 -0.002673  0.010532  0.017836  ... -0.006550  0.028809 -0.005670   \n",
       "794508  0.014023  0.007179  0.007476  ...  0.007305  0.032531 -0.007571   \n",
       "446197 -0.015440  0.016752  0.009769  ... -0.012209  0.033215 -0.021941   \n",
       "794056  0.060736 -0.003931  0.007093  ... -0.002388  0.063318 -0.043061   \n",
       "\n",
       "              57        58        59        60        61        62        63  \n",
       "898657 -0.010917  0.016998 -0.008719  0.024508 -0.019502  0.001892  0.024847  \n",
       "193195 -0.005273 -0.005645 -0.037620 -0.064985  0.021778  0.016151 -0.033996  \n",
       "356268 -0.005670  0.042469 -0.016254  0.056720  0.025408  0.056422 -0.011064  \n",
       "131507 -0.025937  0.021439  0.002099  0.010402  0.021534  0.040205 -0.018626  \n",
       "471772 -0.000078 -0.006012  0.018145  0.013360 -0.006049 -0.022244  0.020143  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "704375 -0.023323  0.026188 -0.025225  0.092622  0.038373 -0.015977  0.023654  \n",
       "199301 -0.012445  0.019952  0.001505  0.015746 -0.009257 -0.002102  0.005940  \n",
       "794508 -0.011182  0.013380 -0.025935  0.001716 -0.019615  0.000288 -0.005441  \n",
       "446197 -0.001283  0.032435 -0.015799 -0.005708 -0.025815 -0.009696  0.001321  \n",
       "794056 -0.001999 -0.006753 -0.039547  0.050413  0.048766  0.043618  0.008088  \n",
       "\n",
       "[804491 rows x 64 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "898657    0\n",
       "193195    0\n",
       "356268    1\n",
       "131507    0\n",
       "471772    1\n",
       "         ..\n",
       "704375    0\n",
       "199301    1\n",
       "794508    0\n",
       "446197    1\n",
       "794056    0\n",
       "Name: label, Length: 804491, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Running ML pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tf_idf',\n",
       "                 TfidfVectorizer(max_features=50000, min_df=2,\n",
       "                                 ngram_range=(1, 2))),\n",
       "                ('mnb', MultinomialNB(alpha=1))])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_mNB_pipeline.fit(train_texts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 out of   1 | elapsed:   25.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tf_idf',\n",
       "                 TfidfVectorizer(max_features=50000, min_df=2,\n",
       "                                 ngram_range=(1, 2))),\n",
       "                ('logit',\n",
       "                 LogisticRegression(C=1, n_jobs=4, random_state=17,\n",
       "                                    verbose=1))])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_logit_pipeline.fit(train_texts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tf_idf',\n",
       "                 TfidfVectorizer(max_features=50000, min_df=2,\n",
       "                                 ngram_range=(1, 2))),\n",
       "                ('ranforest',\n",
       "                 RandomForestClassifier(max_depth=10, n_jobs=4,\n",
       "                                        random_state=15))])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_ranforest_pipeline.fit(train_texts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_svm_pipeline.fit(train_texts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pred_lr = tfidf_logit_pipeline.predict(valid_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pred_mnb = tfidf_mNB_pipeline.predict(valid_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pred_rf = tfidf_ranforest_pipeline.predict(valid_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid_pred_svm = tfidf_svm_pipeline.predict(valid_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(actual, predicted, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix', figsize=(7,7),\n",
    "                          cmap=plt.cm.Blues, path_to_save_fig=None):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(actual, predicted).T\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Predicted label')\n",
    "    plt.xlabel('True label')\n",
    "    \n",
    "    if path_to_save_fig:\n",
    "        plt.savefig(path_to_save_fig, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_valid, valid_pred_lr, tfidf_logit_pipeline.named_steps['logit'].classes_, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.73    100336\n",
      "           1       0.74      0.69      0.71    100787\n",
      "\n",
      "    accuracy                           0.72    201123\n",
      "   macro avg       0.72      0.72      0.72    201123\n",
      "weighted avg       0.72      0.72      0.72    201123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, valid_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.73      0.71    100336\n",
      "           1       0.71      0.67      0.69    100787\n",
      "\n",
      "    accuracy                           0.70    201123\n",
      "   macro avg       0.70      0.70      0.70    201123\n",
      "weighted avg       0.70      0.70      0.70    201123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, valid_pred_mnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.75      0.68    100336\n",
      "           1       0.69      0.56      0.62    100787\n",
      "\n",
      "    accuracy                           0.65    201123\n",
      "   macro avg       0.66      0.65      0.65    201123\n",
      "weighted avg       0.66      0.65      0.65    201123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, valid_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7199574389801265"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, valid_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6987266498610303"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, valid_pred_mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6517205888933638"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, valid_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   1 out of   1 | elapsed:  2.2min finished\n"
     ]
    }
   ],
   "source": [
    "#doc2vec test\n",
    "clf = LogisticRegression(C=1, n_jobs=8, solver='lbfgs', \n",
    "                           random_state=17, verbose=1).fit(X_train, Y_train)\n",
    "y_test_pred_lr = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.59      0.59    100336\n",
      "           1       0.60      0.60      0.60    100787\n",
      "\n",
      "    accuracy                           0.60    201123\n",
      "   macro avg       0.60      0.60      0.60    201123\n",
      "weighted avg       0.60      0.60      0.60    201123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, y_test_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5980668546113572"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test, y_test_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
